{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Model Development\n",
    "\n",
    "In this part, we develop three unique pipelines for predicting backorder. We use the smart sample from Part I to fit and evaluate these pipelines. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os, sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the smart sample here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reload your smart sampling from local file \n",
    "# ----------------------------------\n",
    "pipe_samples = joblib.load('pipe_samples')\n",
    "pipe_samples = pipe_samples.dropna()\n",
    "\n",
    "train_set_downsampled= joblib.load('train-set-downsized')\n",
    "train_set_downsampled = train_set_downsampled.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize/standardize the data if required; otherwise ignore. You can perform this step inside the pipeline (if required). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shapes (X, y):  (2295, 21) (2295,)\n",
      "Testing shapes (X, y):  (574, 21) (574,)\n"
     ]
    }
   ],
   "source": [
    "X = pipe_samples.iloc[:,:-1]\n",
    "y = pipe_samples.went_on_backorder\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "print(\"Training shapes (X, y): \", X_train.shape, y_train.shape)\n",
    "print(\"Testing shapes (X, y): \", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shapes (X, y):  (17276, 21) (17276,)\n",
      "Testing shapes (X, y):  (4320, 21) (4320,)\n"
     ]
    }
   ],
   "source": [
    "X2 = train_set_downsampled.iloc[:,:-1]\n",
    "y2 = train_set_downsampled.went_on_backorder\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.20)\n",
    "print(\"Training shapes (X, y): \", X_train2.shape, y_train2.shape)\n",
    "print(\"Testing shapes (X, y): \", X_test2.shape, y_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing Pipeline\n",
    "\n",
    "In this section, we design an operationalized machine learning pipeline, which includes:\n",
    "\n",
    "* Anomaly detection\n",
    "* Dimensionality Reduction\n",
    "* Train a classification model\n",
    "\n",
    "\n",
    "We are free to use any of the models that we learned in the past or we can use new models. Here is a pool of methods: \n",
    "\n",
    "### Pool of Anomaly Detection Methods (Discussed in M4)\n",
    "1. IsolationForest\n",
    "2. EllipticEnvelope\n",
    "3. LocalOutlierFactor\n",
    "4. OneClassSVM\n",
    "5. SGDOneClassSVM\n",
    "\n",
    "### Pool of Feature Selection Methods (Discussed in M3)\n",
    "\n",
    "1. VarianceThreshold\n",
    "1. SelectKBest with any scoring method (e.g, chi, f_classif, mutual_info_classif)\n",
    "1. SelectKPercentile\n",
    "3. SelectFpr, SelectFdr, or  SelectFwe\n",
    "1. GenericUnivariateSelect\n",
    "2. PCA\n",
    "3. Factor Analysis\n",
    "4. Variance Threshold\n",
    "5. RFE\n",
    "7. SelectFromModel\n",
    "\n",
    "\n",
    "### Classification Methods (Discussed in M1-M2\n",
    "1. Decision Tree\n",
    "2. Random Forest\n",
    "3. Logistic Regression\n",
    "4. Naive Bayes\n",
    "5. Linear SVC\n",
    "6. SVC with kernels\n",
    "7. KNeighborsClassifier\n",
    "8. GradientBoostingClassifier\n",
    "9. XGBClassifier\n",
    "10. LGBM Classifier\n",
    "\n",
    "\n",
    "\n",
    "It is difficult to fit an anomaly detection method in the sklearn pipeline without writing custom codes. For simplicity, we avoid fitting an anomaly detection method within a pipeline. So we can create the workflow in two steps. \n",
    "* Step I: fit an outlier with the training set\n",
    "* Step II: define a pipeline using a feature selection and a classification method. Then cross-validate this pipeline using the training data without outliers. \n",
    "* Note: if your smart sample is somewhat imbalanced, you might want to change the scoring method in GridSearchCV (see the [doc](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)).\n",
    "\n",
    "\n",
    "Once we fit the pipeline with gridsearch, we identify the best model and give an unbiased evaluation using the test set that we created in Part II. For unbiased evaluation we report confusion matrix, precision, recall, f1-score, accuracy, and other measures if you like. \n",
    "\n",
    "**Optional: Those who are interested in writing custom codes for adding an outlier detection method into the sklearn pipeline, please follow this discussion [thread](https://stackoverflow.com/questions/52346725/can-i-add-outlier-detection-and-removal-to-scikit-learn-pipeline).**\n",
    "\n",
    "\n",
    "**Note:** <span style='background:yellow'>We will be using Grid Search to find the optimal parameters of the pipelines.</span>\n",
    "\n",
    "You can add more notebook cells or import any Python modules as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your 1st pipeline \n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation\n",
    "  \n",
    "Add cells as needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of outliers = 1727\n"
     ]
    }
   ],
   "source": [
    "# Add anomaly detection code  (Question #E201)\n",
    "# ----------------------------------\n",
    "iso_forest = IsolationForest(contamination=0.1).fit(X_train2, y_train2)\n",
    "iso_outliers = iso_forest.predict(X_train2)==-1\n",
    "print(f\"Num of outliers = {np.sum(iso_outliers)}\")\n",
    "X_trainiso = X_train2[~iso_outliers]\n",
    "y_trainiso = y_train2[~iso_outliers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('PCA', PCA()),\n",
       "                                       ('LogisticRegression',\n",
       "                                        LogisticRegression(max_iter=100000))]),\n",
       "             n_jobs=5,\n",
       "             param_grid={'LogisticRegression__C': [0.1, 1, 10, 100, 1000],\n",
       "                         'PCA__n_components': [3, 5, 10, 15, 20]})"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add codes for feature selection and classification pipeline with grid search  (Question #E202)\n",
    "# ----------------------------------\n",
    "pca_components = 20\n",
    "logistic = LogisticRegression(max_iter = 10000, tol = 0.1)\n",
    "pipe = Pipeline(steps=[(\"PCA\", PCA(n_components = pca_components)), (\"LogisticRegression\", logistic)])\n",
    "\n",
    "\n",
    "param_grid = {'PCA__n_components': [3,5,10,15,20],\n",
    "              'LogisticRegression__C': [.1,1,10,100,1000]}    \n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf_pipe = Pipeline([('PCA', PCA()), ('LogisticRegression',LogisticRegression(max_iter = 100000))])\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model_grid = GridSearchCV(clf_pipe, param_grid = param_grid, cv = 10, n_jobs = 5)\n",
    "model_grid.fit(X_trainiso, y_trainiso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1\n",
      "0  219   73\n",
      "1   28  254\n",
      "Accuracy: 0.82\n",
      "Precision: 0.83\n",
      "Recall: 0.83\n",
      "F1-Score: 0.82\n"
     ]
    }
   ],
   "source": [
    "# Given an unbiased evaluation  (Question #E203)\n",
    "# ----------------------------------\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "predicted_y = model_grid.predict(X_test)\n",
    "print(pd.DataFrame(confusion_matrix(y_test, predicted_y)))\n",
    "print(\"Accuracy:\", np.round(accuracy_score(y_test, predicted_y), 2))\n",
    "print(\"Precision:\", np.round(precision_score(y_test, predicted_y, average='weighted'), 2))\n",
    "print(\"Recall:\", np.round(precision_score(y_test, predicted_y, average='weighted'), 2))\n",
    "print(\"F1-Score:\", np.round(f1_score(y_test, predicted_y, average='weighted'), 2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the optimal hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19    {'LogisticRegression__C': 100, 'PCA__n_compone...\n",
      "Name: params, dtype: object\n",
      "optimal parameters = C = 100, n_components = 20, performance = mean_test_score = .814394\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'LogisticRegression__C': 100, 'PCA__n_compone...</td>\n",
       "      <td>0.814394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  mean_test_score\n",
       "19  {'LogisticRegression__C': 100, 'PCA__n_compone...         0.814394"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E204)\n",
    "# ---------------------------------------------\n",
    "df = pd.DataFrame(model_grid.cv_results_)\n",
    "\n",
    "\n",
    "best = df[df['rank_test_score'] == 1]\n",
    "print(best.params)\n",
    "\n",
    "print('optimal parameters = C = 100, n_components = 20, performance = mean_test_score = .814394')\n",
    "best[['params','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"background: yellow;\">Commit your code!</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your 2nd pipeline\n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of outliers = 5198\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function sklearn.base.BaseEstimator.get_params(self, deep=True)>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add anomaly detection code  (Question #E205)\n",
    "# ----------------------------------\n",
    "from sklearn.svm import OneClassSVM\n",
    "svm = OneClassSVM(kernel='rbf', nu = .3).fit(X_train2, y_train2)\n",
    "svm_outliers = svm.predict(X_train2)==-1\n",
    "print(f\"Num of outliers = {np.sum(svm_outliers)}\")\n",
    "X_svm = X_train2[~svm_outliers]\n",
    "y_svm = y_train2[~svm_outliers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_search.py:921: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.85022146 0.85022146 0.85080134        nan\n",
      "        nan 0.85668102 0.85626711 0.85593557        nan        nan\n",
      " 0.85577131 0.85618522 0.85452877        nan        nan 0.86123585\n",
      " 0.86181587 0.86065611        nan        nan 0.85833781 0.86007609\n",
      " 0.85734471        nan        nan 0.85403023 0.85411301 0.85444427\n",
      "        nan        nan 0.85858403 0.85808721 0.85841868        nan\n",
      "        nan 0.85800497 0.85825332 0.85783921        nan        nan\n",
      " 0.85875035 0.85808851 0.85833583        nan        nan 0.8564324\n",
      " 0.85601849 0.85850276]\n",
      "  category=UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('GenericUnivariateSelect',\n",
       "                                        GenericUnivariateSelect(mode='k_best')),\n",
       "                                       ('DecisionTreeClassifier',\n",
       "                                        DecisionTreeClassifier())]),\n",
       "             n_jobs=5,\n",
       "             param_grid={'DecisionTreeClassifier__criterion': ['entropy',\n",
       "                                                               'gini'],\n",
       "                         'DecisionTreeClassifier__max_depth': [5, 7, 8, 12, 15],\n",
       "                         'GenericUnivariateSelect__mode': ['precentile',\n",
       "                                                           'k_best', 'fpr',\n",
       "                                                           'fdr', 'fwe']})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add codes for feature selection and classification pipeline with grid search  (Question #E206)\n",
    "# ----------------------------------\n",
    "from sklearn.feature_selection import GenericUnivariateSelect\n",
    "decision = DecisionTreeClassifier()\n",
    "pipe = Pipeline(steps=[(\"GenericUnivariateSelect\", GenericUnivariateSelect(f_classif)), (\"DecisionTreeClassifier\", decision)])\n",
    "\n",
    "\n",
    "param_grid2 = {\"GenericUnivariateSelect__mode\":['precentile','k_best','fpr','fdr','fwe'],\n",
    "              'DecisionTreeClassifier__max_depth': [5,7,8,12,15],\n",
    "              'DecisionTreeClassifier__criterion': ['entropy', 'gini']}    \n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf_pipe2 = Pipeline([('GenericUnivariateSelect', GenericUnivariateSelect(f_classif, mode = 'k_best')), ('DecisionTreeClassifier',DecisionTreeClassifier(criterion = 'gini'))])\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model_grid2 = GridSearchCV(clf_pipe2, param_grid = param_grid2, cv = 10, n_jobs = 5)\n",
    "model_grid2.fit(X_svm, y_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1\n",
      "0  239   53\n",
      "1   17  265\n",
      "Accuracy: 0.88\n",
      "Precision: 0.88\n",
      "Recall: 0.88\n",
      "F1-Score: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Given an unbiased evaluation  (Question #E207)\n",
    "# ----------------------------------\n",
    "y_pred = model_grid2.predict(X_test)\n",
    "print(pd.DataFrame(confusion_matrix(y_test, y_pred)))\n",
    "print(\"Accuracy:\", np.round(accuracy_score(y_test, y_pred), 2))\n",
    "print(\"Precision:\", np.round(precision_score(y_test, y_pred, average='weighted'), 2))\n",
    "print(\"Recall:\", np.round(precision_score(y_test, y_pred, average='weighted'), 2))\n",
    "print(\"F1-Score:\", np.round(f1_score(y_test, y_pred, average='weighted'), 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the optimal hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18    {'DecisionTreeClassifier__criterion': 'entropy...\n",
      "Name: params, dtype: object\n",
      "optimal params = entropy, max_depth = 12, mode = fdr, performance mean_test_score = .861816\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'DecisionTreeClassifier__criterion': 'entropy...</td>\n",
       "      <td>0.861816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  mean_test_score\n",
       "18  {'DecisionTreeClassifier__criterion': 'entropy...         0.861816"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E208)\n",
    "# ---------------------------------------------\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame(model_grid2.cv_results_)\n",
    "\n",
    "\n",
    "best2 = df2[df2['rank_test_score'] == 1]\n",
    "print(best2.params)\n",
    "\n",
    "\n",
    "best2\n",
    "\n",
    "print('optimal params = entropy, max_depth = 12, mode = fdr, performance mean_test_score = .861816')\n",
    "best2[['params','mean_test_score']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"background: yellow;\">Commit your code!</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your 3rd pipeline\n",
    "  * Anomaly detection\n",
    "  * Dimensionality reduction\n",
    "  * Model training/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add anomaly detection code  (Question #E209)\n",
    "# ----------------------------------\n",
    "lof_labels = LocalOutlierFactor(n_neighbors=10).fit_predict(X_train2, y_train2)\n",
    "inliers = lof_labels == 1\n",
    "X_clean = X_train2[inliers]\n",
    "y_clean = y_train2[inliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('FactorAnalysis', FactorAnalysis()),\n",
       "                                       ('RandomForestClassifier',\n",
       "                                        RandomForestClassifier())]),\n",
       "             n_jobs=5,\n",
       "             param_grid={'FactorAnalysis__n_components': [5, 10, 15, 20],\n",
       "                         'RandomForestClassifier__n_estimators': [5, 10, 15,\n",
       "                                                                  20]})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add codes for feature selection and classification pipeline with grid search  (Question #E210)\n",
    "# ----------------------------------\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "pipe = Pipeline(steps=[(\"FactorAnalysis\", FactorAnalysis(random_state = 5)), (\"RandomForestClassifier\", rf)])\n",
    "\n",
    "\n",
    "param_grid3 = {'FactorAnalysis__n_components': [5,10,15,20],\n",
    "              'RandomForestClassifier__n_estimators': [5,10,15,20]}    \n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf_pipe3 = Pipeline([('FactorAnalysis', FactorAnalysis(random_state = 0)), ('RandomForestClassifier',RandomForestClassifier())])\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model_grid3 = GridSearchCV(clf_pipe3, param_grid = param_grid3, cv = 10, n_jobs = 5)\n",
    "model_grid3.fit(X_clean, y_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1\n",
      "0  278   14\n",
      "1   10  272\n",
      "Accuracy: 0.96\n",
      "Precision: 0.96\n",
      "Recall: 0.96\n",
      "F1-Score: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Given an unbiased evaluation  (Question #E211)\n",
    "# ----------------------------------\n",
    "y_pred3 = model_grid3.predict(X_test)\n",
    "print(pd.DataFrame(confusion_matrix(y_test, y_pred3)))\n",
    "print(\"Accuracy:\", np.round(accuracy_score(y_test, y_pred3), 2))\n",
    "print(\"Precision:\", np.round(precision_score(y_test, y_pred3, average='weighted'), 2))\n",
    "print(\"Recall:\", np.round(precision_score(y_test, y_pred3, average='weighted'), 2))\n",
    "print(\"F1-Score:\", np.round(f1_score(y_test, y_pred3, average='weighted'), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center>Record the optimal hyperparameters and performance resulting from this pipeline.</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11    {'FactorAnalysis__n_components': 15, 'RandomFo...\n",
      "Name: params, dtype: object\n",
      "optimal parameters = param_FactorAnalysis__n_components = 15 param_RandomForestClassifier__n_estimators = 20, mean test score = .889135\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'FactorAnalysis__n_components': 15, 'RandomFo...</td>\n",
       "      <td>0.889135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               params  mean_test_score\n",
       "11  {'FactorAnalysis__n_components': 15, 'RandomFo...         0.889135"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detail Hyperparameters and Results below  (Question #E212)\n",
    "# ---------------------------------------------\n",
    "\n",
    "df3 = pd.DataFrame(model_grid3.cv_results_)\n",
    "\n",
    "\n",
    "best3 = df3[df3['rank_test_score'] == 1]\n",
    "print(best3.params)\n",
    "\n",
    "\n",
    "print('optimal parameters = param_FactorAnalysis__n_components = 15 param_RandomForestClassifier__n_estimators = 20, mean test score = .889135')\n",
    "best3\n",
    "\n",
    "best3[['params','mean_test_score']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare these three pipelines and discuss your findings"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Write your analysis in this cell (Question #E213)\n",
    "# ----------------------------------\n",
    "\n",
    "##I originally used my pipe_samples subbset to form my pipelines, then applied my smart samples\n",
    "\n",
    "My third pipeline is arguably the best of mine. We see a .96 score regarding accuracy, percision, f1, and recall. \n",
    "\n",
    "My second best pipeline was my second pipeline, with a .88 score regarding accuracy, percision, f1, and recall\n",
    "\n",
    "My lowest performing pipeline was the first one a score 0f .82 regarding acurracy and F1, and .83 for percision and recall. \n",
    "\n",
    "Accuracy is the number of data points that the model predicted right over all of the data points, thus a higher accuracy is better. Precision is a measure of the condition of true positives predicted by our model. A higher precision implies less error, thus a higher precision is preferable to a lower one.F1, essentially, is a joining of precision and recall, with a perfect model returning a score of 1. My highest F1 score was .96, pretty close!\n",
    "\n",
    "\n",
    "The combination of methods that created my highest preforming pipleine was..\n",
    "\n",
    "\n",
    "Anomaly detection - localOutlierFactor\n",
    "Feature selection - FactorAnalysis\n",
    "Classification Method - RandomForest\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"background: yellow;\">Commit your code!</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle the required pipeline/models for Part III."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bestpiperevised']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "joblib.dump(model_grid3.best_estimator_,'bestpiperevised')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have made a few commits so far of this project.  \n",
    "**Definitely make a commit of the notebook now!**  \n",
    "Comment should be: `Final Project, Checkpoint - Pipelines done`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook!\n",
    "## Then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
