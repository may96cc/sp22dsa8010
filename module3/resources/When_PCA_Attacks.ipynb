{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A walk through example of PCA being counter productive to classification tasks\n",
    "\n",
    "Recall that separability is a key thing we strive for when learning classifiers (which find decision boundaries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "np.random.seed(18937)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we have this sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_per_class = 320\n",
    "\n",
    "# Builds two class data set in 2-D space\n",
    "dataset2 = np.vstack([\n",
    "  np.hstack([np.random.multivariate_normal([0,5], [[3, 1], [1, 16]], num_per_class), np.zeros((num_per_class, 1))]),\n",
    "  np.hstack([np.random.multivariate_normal([5,0], [[3, 1], [1, 16]], num_per_class), np.ones((num_per_class, 1))])\n",
    "])\n",
    "\n",
    "np.random.shuffle(dataset2)\n",
    "\n",
    "plt.scatter(dataset2[:, 0], dataset2[:, 1], c=dataset2[:, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Carve out the classes for feature X-axis\n",
    "d0 = dataset2[np.where(dataset2[:, 2]==0), 0].reshape(num_per_class)\n",
    "d1 = dataset2[np.where(dataset2[:, 2]==1), 0].reshape(num_per_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histograms of Original First Dimension**\n",
    "\n",
    "We can see the first feature provides a degree of separability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the buckets across \n",
    "bins = numpy.linspace(-4, 10, 30)\n",
    "\n",
    "pyplot.hist(d0, bins, alpha=0.5, label='x')\n",
    "pyplot.hist(d1, bins, alpha=0.5, label='y')\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, let's look at he data in PCA space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2_PCA = PCA().fit_transform(dataset2[:, :2])\n",
    "\n",
    "plt.scatter(dataset2_PCA[:, 0], dataset2_PCA[:, 1], c=dataset2[:, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine you are going to build a decision tree classifer, then you have to make decision along a single dimension.  \n",
    "The PCA transformation appears to have increased the overlap of the classes in both dimensions.  \n",
    "Furthermore, it does not truly appear to have increased separability at all.\n",
    "\n",
    "Let's look at the histograms of the features after PCA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histograms of First Princpal Component**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carve out the classes for feature X-axis\n",
    "d0 = dataset2_PCA[np.where(dataset2[:, 2]==0), 0].reshape(num_per_class)\n",
    "d1 = dataset2_PCA[np.where(dataset2[:, 2]==1), 0].reshape(num_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the buckets across \n",
    "bins = numpy.linspace(-12, 15, 30)\n",
    "\n",
    "pyplot.hist(d0, bins, alpha=0.5, label='x')\n",
    "pyplot.hist(d1, bins, alpha=0.5, label='y')\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Histograms of Second Princpal Component**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the buckets across \n",
    "bins = numpy.linspace(-7, 8, 30)\n",
    "\n",
    "# Carve out the classes for feature X-axis\n",
    "d0 = dataset2_PCA[np.where(dataset2[:, 2]==0), 1].reshape(num_per_class)\n",
    "d1 = dataset2_PCA[np.where(dataset2[:, 2]==1), 1].reshape(num_per_class)\n",
    "\n",
    "pyplot.hist(d0, bins, alpha=0.5, label='x')\n",
    "pyplot.hist(d1, bins, alpha=0.5, label='y')\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We see that the overlap along each dimension has increased after PCA!\n",
    "\n",
    "This is an example when PCA can become a counter productive technique when PCA oversimplifies  \n",
    "the relations between different pairs of features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
